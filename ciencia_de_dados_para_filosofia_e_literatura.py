# -*- coding: utf-8 -*-
"""Ciencia de dados para filosofia e literatura

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11zHORweGuUZkElFgCM7LQmyVmqzlAZs1

## TUTORIAL
1. Execute a célula das bibliotecas (vai demorar um pouquinho porque é a primeira)
2. Execute a célula do script
3. Execute a célula com o nome do autor que preferir.

Voce pode substituir por outros autores, por exemplo: Se voce quiser o Charles Chaplin, basta substituir por Charles_Chaplin, sempre separando por underline, não por espaço

## Importar as bibliotecas
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
!pip install reportlab -q
from reportlab.pdfgen import canvas
from reportlab.lib.units import cm
from reportlab.lib import colors

"""## Script"""

def citacoes(nome, pag): #Definindo nossa função
  autor_cont = 0 #Isso aqui serve para a informação do autor aparecer só uma vez, é um contador
  url = 'https://www.pensador.com/autor/' #Link que usaremos para webscraping
  autor = str(nome) #Nome do autor
  autor_nome = autor.upper().replace('_', ' ') #Trocando _ por espaco
  pag = int(pag) #Número de páginas
  frases_juntas = '' #Para depois juntar as frases
  frase_final = [] #Para plotar a frase inteira depois
  stop_words = ''' a, se, disse, apenas, melhor, acontece, agora, ainda, alguém, algum, alguma, algumas, alguns, ampla, amplas, amplo, amplos, ante, antes, ao, aos, após, aquela, aquelas, aquele, aqueles, aquilo, as, até, através,
  cada, coisa, coisas, com, como, conhece-te, contra, contudo, da, daquele, daqueles, das, de, dela, delas, dele, deles, depois, dessa, dessas, desse, desses, desta, destas, deste, deste, destes, deve, devem, devendo, dever, deverá, deverão, deveria, deveriam, devia, deviam, disse, disso, disto, dito, diz, dizem,
  do, dos, e, é, ela, elas, ele, eles, em, enquanto, entre, era, essa, essas, esse, esses, esta, está, estamos, estão, estas, estava, estavam, estávamos, este, estes, estou, eu, fazendo, fazer, feita, feitas, feito, feitos, foi, for, foram, fosse, fossem, grande, grandes, há, isso, isto, já, la, lá, lhe, lhes, lo,
  mas, me, mesma, mesmas, mesmo, mesmos, meu, meus, minha, minhas, muita, muitas, muito, muitos, na, não, nas, nem, nenhum, nessa, nessas, nesta, nestas, ninguém, no, nos, nós, nossa, nossas, nosso, nossos, num, numa, nunca, o, os, ou, outra, outras, outro, outros,
  para, pela, pelas, pelo, pelos, pequena, pequenas, pequeno, pequenos, per, perante, pode, pude, podendo, poderia, poderiam, podia, podiam, pois, por, porém, porque, posso, pouca, poucas, pouco, poucos, primeiro, primeiros, própria, próprias, próprio, próprios, quais, qual, quando, quanto, quantos, que, quem,
  são, se, seja, sejam, sem, sempre, sendo, será, serão, seu, seus, si, sido, só, sob, sobre, sua, suas, talvez, também, tampouco, te, tem, tendo, tenha, ter, teu, teus, ti, tido, tinha, tinham, toda, todas, todavia, todo, todos, tu, tua, tuas, tudo, última, últimas, último, últimos, um, uma, umas, uns,
  vendo, ver, vez, vindo, vir, vos, vós,''' #Palavras que serão retiradas
  print(f'FRASES DE {autor_nome}\n') #Mostrando o nome do autor
  for i in range(1, pag+1): #Uma repetição pra fazer o processo inteiro de webscraping
    url_final = url + autor + '/' + str(i) + '/' #Alterando o link para ter o nome do autor e o numero de paginas
    link =f'https://pt.wikipedia.org/wiki/{autor}'
    req = requests.get(link)
    soup = BeautifulSoup(req.content, 'html.parser')
    numero = []
    html = soup.find('p')
    sobre2 = html.text
    tirar = soup.find_all('a')
    for i in range(len(tirar)):
      retirar = tirar[i].text
      if '[' and ']'in retirar:
        numero.append(retirar)
      for j in numero:
        if j in sobre2:
          sobre2 = sobre2.replace(f'{j}', '')
    req = requests.get(url_final)
    soup = BeautifulSoup(req.content, 'html.parser')
 
    frase_lista = soup.find_all('p', class_='frase fr')
    sobre_lista = soup.find_all('span', class_='text')
    sobre = str(sobre_lista).split('>')[1][:-6] #Limpeza de dados
    if autor_cont < 1: #Fazer a descrição do autor uma única vez, se não vai repetir sempre
      autor_cont +=1
      print(f'Sobre o autor: {sobre}\n')
      print(f'Wikipedia: {sobre2}\n\n\n')
    else:
      autor_cont +=0
      print('')
    for j in range(len(frase_lista)): #Unir todas as frases numa string só
      frase = str(frase_lista[j]).split('>')[1][:-3]
      print(f'{frase}\n')
      frases_juntas += frase
      frases_juntas2 = frases_juntas.replace('.', ' ').replace(';','').lower() #Tirar ponto, virgula e colocar tudo minusculo
    frases_juntas2 = frases_juntas2.split() #separar em palavras
  for palavra in frases_juntas2: #Jogando essas palavras numa lista
    if len(palavra) > 5 and palavra not in stop_words:
      frase_final.append(palavra)
  df = pd.DataFrame(np.array(frase_final)) #Criando um dataframe com essas palavras
  df.columns = ['coluna']
  grafico = df.value_counts()[:5].plot(kind='barh',title=f'Termos mais frequentes ({autor_nome})', xlabel='').get_figure() #Criando o gráfico de barras
  grafico.savefig(f'Gráfico {autor}',bbox_inches='tight')
  nuvem = WordCloud(stopwords=stop_words, background_color='black',width=1600, height=800).generate(' '.join(df['coluna'])) #Criando uma nuvem de palavras
  fig, ax = plt.subplots(figsize=(10,6))
  ax.imshow(nuvem, interpolation='bilinear')
  ax.set_axis_off()
  fig.savefig(f'Nuvem de palavras {autor}',bbox_inches='tight')
  plt.imshow(nuvem); #Mostrando a nuvem

  #Criando um pdf
  pdf = canvas.Canvas(f'PDF {autor}.pdf')
  pdf.setFont('Helvetica-Bold', 14)
  pdf.drawString(175,800, f'Resumo sobre {autor_nome} em PDF')
  pdf.setFont('Helvetica',12)
  if len(sobre) >=70:
    pdf.drawString(20,750, f'{sobre[:70]}')
  else:
    pdf.drawString(20,750, f'{sobre}')

  pdf.setFont('Helvetica-Bold',12)
  pdf.drawString(20,700, 'Top 10 Citações:')
  for k in range(len(frase_lista[:10])):
    frase = str(frase_lista[k]).split('>')[1][:-3]
    pdf.setFont('Helvetica',10)
    ultima_frase = 650 - k*20
    if len(frase) >=120:
      pont = '...'
    else:
      pont = '.' 
    pdf.drawString(20,ultima_frase, f'{frase[:120]}{pont}')
  pdf.drawImage(f'Gráfico {autor}.png', 20, 650-ultima_frase, width=280, height=220)
  pdf.drawImage(f'Nuvem de palavras {autor}.png', 320, 650-ultima_frase, width=250, height=220)
  pdf.save()

"""## Instruções

* O nome do autor deve ser escrito sem acento e com underline no lugar do espaço;

* Utilize o número de páginas com cuidado, pois nem todos os autores irão gerar novas citações.

* Quanto menor o número de páginas, mais precisas serão as "top 10 citações" no relatório em PDF, por outro lado, conterá menos palavras para o gráfico e a nuvem de palavras. É um trade-off a ser tratado pelo usuário, conforme sua preferência. **A minha recomendação é utilizar apenas uma página, pois reflete melhor as principais citações do autor, além de já ser suficiente para o gráfico e a nuvem de palavras.** Porém depende muito do autor, um exemplo é o filósofo Sócrates, onde apenas 1 página nos traz poucos resultados satisfatórios, mas com 3 páginas conseguimos insights interessantes sobre o autor. Então faça testes com as quantidades de páginas

## Faça bom proveito!!
Espero que esse notebook seja útil e lhe ajude nos seus estudos!
"""

citacoes('Adam_Smith', 1) #Adam Smith

citacoes('Karl_Marx',1) #Karl Marx

citacoes('Socrates', 3) #Sócrates

citacoes('Carl_Sagan',1) #Carl Sagan